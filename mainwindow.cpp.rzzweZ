#include "mainwindow.h"
#include "ui_mainwindow.h"
#include <QFileDialog>
#include <QMessageBox>
#include <QPixmap>
#include <QImage>
#include <QVector>
#include <QQueue>

#include <iostream>
#include <fstream>
#include <list>
#include <string>



// onnxruntime library
#include<onnxruntime_cxx_api.h>


const int targetWidth = 384;       // image scaled width
const int targetHeight = 384;      // image scaled height

// Define normalization parameters
std::array<float,3> image_mean = {0.48145466, 0.4578275, 0.40821073};
std::array<float,3> image_std = {0.26862954, 0.26130258, 0.27577711};


// Path to your ONNX model file
const char* modelVisionPath = "/home/tensor/caption_d/vision_model.onnx";
const char* modelTextPath = "/home/tensor/caption_d/text_decoder_model.onnx";

// Tokenizer file path
const char* TokenizerPath = "/home/tensor/caption_d/vocab.txt";

std::list<std::string> text_tock;




std::list<std::string> get_tokens(){
    std::ifstream file(TokenizerPath);
    // Check if the file is open
    if (!file.is_open()) {
        qDebug() << "Error opening vocab text file!" ;
    }

    std::list<std::string> lines;
    // Read each line from the file and store it in the list
    std::string line;
    while (std::getline(file, line)) {
        lines.push_back(line);
    }

    // Close the file
    file.close();
    return lines;
}


std::array<float,  1 * 3 * targetHeight * targetWidth> preprocess(QImage img){
    QImage scaledImage = img.scaled(targetWidth, targetHeight);
    scaledImage = scaledImage.convertToFormat(QImage::Format_RGB888);
    // Creating a 3D array
    std::vector<std::vector<std::vector<float>>> originalArray(targetHeight, std::vector<std::vector<float>>(targetWidth, std::vector<float>(3, 0)));
    // Transposing the array (swapping dimensions)
    std::vector<std::vector<std::vector<float>>> transposedArray(3, std::vector<std::vector<float>>(targetHeight, std::vector<float>(targetWidth, 0)));


    // Normalize image to mean and standard deviation
    for (int y = 0; y < scaledImage.height(); ++y){
        for (int x = 0; x < scaledImage.width(); ++x)
        {
            QColor pixelColor(scaledImage.pixel(x, y));
            float r = (pixelColor.redF() - image_mean[0]) / image_std[0];
            float g = (pixelColor.greenF() - image_mean[1]) / image_std[1];
            float b = (pixelColor.blueF() - image_mean[2]) / image_std[2];

            originalArray[x][y][0]=r;
            originalArray[x][y][1]=g;
            originalArray[x][y][2]=b;
        }

    }

    // adjust the array to model input shape
    for (int c = 0; c < 3; ++c) {
        for (int i = 0; i < targetHeight; ++i) {
            for (int j = 0; j < targetWidth; ++j) {
                transposedArray[c][i][j] = originalArray[i][j][c];
            }
        }
    }

    // Convert to std::array
    std::array<float, 1 * 3 * targetHeight * targetWidth> input_array;

    size_t index = 0;
    for (const auto &outerVec : transposedArray) {
        for (const auto &middleVec : outerVec) {
            for (const auto &innerVal : middleVec) {
                input_array[index++] = innerVal;
            }
        }
    }
    //qDebug() << "pixel value"<< (input_array[65]);

    return input_array;


}


MainWindow::MainWindow(QWidget *parent)
    : QMainWindow(parent)
    , ui(new Ui::MainWindow)
{
    Ort::RunOptions runOptions;
    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, "ONNXRuntimeModel");
    // Create a session options object
    Ort::SessionOptions session_options;
    // Create a session using the model path and session options to load vision model
    Ort::Session vision_model_session{env, modelVisionPath, session_options};

    Ort::Session text_model_session{env, modelTextPath, session_options};

    text_tock = get_tokens();


    int intArray[4] = {25000, 25007, 25004, 250004};
    int arrayLength = sizeof(intArray) / sizeof(int);
    std::string concatenatedString;

    for(int i=0; i<arrayLength; i++){
        auto it = std::next(text_tock.begin(), intArray[i]);
        concatenatedString += *it + " ";

    }
    // qDebug() << "pixel value"<< concatenatedString;






    // // Ort::TypeInfo inputInfo = onnx_session.GetInputTypeInfo(0);
    // // Ort::TypeInfo outputInfo = onnx_session.GetOutputTypeInfo(0);




    // std::vector<int64_t> inputShape{ 1, 3, 384, 384 };
    // const std::array<int64_t, 3> outputShape = { 1, 577, 1024 };

    // // define array
    // std::array<float, 1*3*384*384> input;
    // std::array<float, 1*577*1024> results;

    // // define Tensor
    // auto memory_info = Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeCPU);
    // auto inputTensor = Ort::Value::CreateTensor<float>(memory_info, input.data(), input.size(), inputShape.data(), inputShape.size());
    // auto outputTensor = Ort::Value::CreateTensor<float>(memory_info, results.data(), results.size(), outputShape.data(), outputShape.size());


    // // define names
    // Ort::AllocatorWithDefaultOptions ort_alloc;
    // Ort::AllocatedStringPtr inputName = onnx_session.GetInputNameAllocated(0, ort_alloc);
    // Ort::AllocatedStringPtr outputName = onnx_session.GetOutputNameAllocated(0, ort_alloc);

    // const std::array<const char*, 1> inputNames = { inputName.get()};
    // const std::array<const char*, 1> outputNames = { outputName.get()};
    // inputName.release();
    // outputName.release();

    // // run inference

    //    onnx_session.Run(runOptions, inputNames.data(), &inputTensor, 1, outputNames.data(), &outputTensor, 1);




    qDebug() << "Hello to the world ";



    ui->setupUi(this);
}

MainWindow::~MainWindow()
{
    delete ui;
}
QString file_name;
void MainWindow::on_pushButton_clicked()
{

    file_name = QFileDialog::getOpenFileName(this, tr("Open File"), QDir::homePath(), tr("Images (*.png *.xpm *.jpg)"));
    if(!file_name.isEmpty()){
        //open prompt and display image
        QMessageBox::information(this, "...", file_name);
        QImage img(file_name);
        QPixmap pix = QPixmap::fromImage(img);

        int w = ui->label_pic->width();
        int h = ui->label_pic->height();

        ui->label_pic->setPixmap(pix.scaled(w,h,Qt::KeepAspectRatio));



    }

}



void MainWindow::on_predict_clicked()
{
    if(!file_name.isEmpty()){
        QImage img(file_name);

        std::array<float, 1 * 3 * targetHeight * targetWidth> img_array = preprocess(img);


        QString text = QString::number(img.width());
        ui-> label -> setText(text);
    }
}
